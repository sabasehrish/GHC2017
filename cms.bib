@article{chep, 
  title={{Big Data in HEP: A comprehensive use case study}}, 
  author={Oliver Gutsche and Matteo Cremonesi and Bo Jayatilaka and Jim Kowalkowski and Saba Sehrish and Cristina Mantilla Suárez and Nhan Tranl and Peter Elmer and Jim Pivarski and Alexey Svyatkovskiy}, 
  journal={To be published in the proceedings of CHEP 2016}
}

@article{h5spark,
  title={{H5Spark: Bridging the I/O Gap between Spark and Scientific Data Formats on HPC Systems}},
  author={Liu, Jialin and Racah, Evan and Koziol, Quincey and Canon, Richard Shane},
  url   = "https://github.com/valiantljk/h5spark",
  journal = {Cray User Group (CUG'16)}
}

@Misc{spark-hdf5,
  title={{HDF5 Plugin for Spark.}}, 
  howpublished = {\url{https://github.com/LLNL/spark-hdf5}}
}

@Misc{spark-hdf5-cms,
  title={{Github repository for the CMS Dark Matter Analysis Code using Spark.}},
  howpublished = {\url{https://github.com/sabasehrish/spark-hdf5-cms}}
}

@Misc{numpy,
  title={{NumPy.}},
  howpublished = {\url{http://www.numpy.org}}
}

@Misc{mpi4py,
  title={{MPI for Python.}},
  howpublished = {\url{http://mpi4py.scipy.org}}
}

@Misc{h5py,
  title={{HDF5 for Python.}},
  howpublished = {\url{http://www.h5py.org}}
}


@ONLINE{hdf5,
    author = {{The HDF Group}},
    title = "{Hierarchical Data Format, version 5}",
    year = {1997-2017},
}

@Misc{hyperslab,
  title={{Hyperslab Tutorial.}},
  howpublished = {\url{https://support.hdfgroup.org/HDF5/Tutor/select.html}}
}

@unpublished{cmsimg,
      author        = "Mc Cauley, Thomas",
      title         = "{Higgs boson produced via vector boson fusion event
                       recorded by CMS (Run 2, 13 TeV)}",
      month         = "Aug",
      year          = "2016",
      reportNumber  = "CMS-PHO-EVENTS-2016-007",
      url           = "http://cds.cern.ch/record/2210658",
      note          = "CMS Collection.",
}

@Misc{spark-notes, 
  title= {{Mastering Apache Spark 2.0.}}, 
  author=  {Jacek Laskowski}, 
  howpublished = {\url{https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details}}}

@book{sparkcookbook,
   title = {{Spark Cookbook.}},
   author = "Rishi Yadav",
   publisher = "Packt Publishing",
   isbn = "10:1-78398-707-3",
   year = 2015
}

@inproceedings{spark1,
 author = {Zaharia, Matei and Chowdhury, Mosharaf and Franklin, Michael J. and Shenker, Scott and Stoica, Ion},
 title = {{Spark: Cluster Computing with Working Sets}},
 booktitle = {Proceedings of the 2Nd USENIX Conference on Hot Topics in Cloud Computing},
 series = {HotCloud'10},
 year = {2010},
 location = {Boston, MA},
 pages = {10--10},
 numpages = {1},
 url = {http://dl.acm.org/citation.cfm?id=1863103.1863113},
 acmid = {1863113},
 publisher = {USENIX Association},
 address = {Berkeley, CA, USA},
} 

@Misc{spark,
  title = {Spark.},
  howpublished = {\url{https://spark.apache.org}},
}

@Misc{dataframe,
  title = {{DataFrame API}.},
  howpublished = {\url{http://spark.apache.org/docs/latest/sql-programming-guide.html}},
}

@inproceedings{sparksql,
 author = {Armbrust, Michael and Xin, Reynold S. and Lian, Cheng and Huai, Yin and Liu, Davies and Bradley, Joseph K. and Meng, Xiangrui and Kaftan, Tomer and Franklin, Michael J. and Ghodsi, Ali and Zaharia, Matei},
 title = {{Spark SQL: Relational Data Processing in Spark}},
 booktitle = {Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data},
 series = {SIGMOD '15},
 year = {2015},
 isbn = {978-1-4503-2758-9},
 location = {Melbourne, Victoria, Australia},
 pages = {1383--1394},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2723372.2742797},
 doi = {10.1145/2723372.2742797},
 acmid = {2742797},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {data warehouse, databases, hadoop, machine learning, spark},
}

@Misc{hadoop,
  title = {Hadoop.},
  howpublished={\url{http://hadoop.apache.org}}
}

@Misc{arma,
  title = {{Armadillo - C++ linear algebra library.}},
  howpublished={\url{http://arma.sourceforge.net}}
}

@Misc{lem, 
  title={{Library Event Matching event classification algorithm for electron neutrino interactions in the NOvA detectors}}, 
  howpublished={\url{http://arxiv.org/abs/1501.00968v2}}
}

@Misc{sparkarchi,
  title={{Distributed Systems Architecture: Spark Architecture}},
  howpublished={\url{http://0x0fff.com/spark-architecture/}}
}

@Misc{yarn,
  title={{YARN - Yet Another Resource Negotiator}},
  howpublished={\url{http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html}}
}

@MISC{hdfs,
  title={{HDFS - Hadoop Distributed File System}},
  howpublished={\url{http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html}}
}

@MISC{nersc-spark,
  title={{Spark Distributed Analytics Framework at NERSC}},
  howpublished={\url{https://www.nersc.gov/users/data-analytics/data-analytics/spark-distributed-analytic-framework}}
}

@MISC{nova, 
  title={{NOvA Neutrino Experiment}},
  howpublished={\url{http://www-nova.fnal.gov}}
}

@article{HEPana,
      author         = "Bhat, Pushpalatha C.",
      title          = "{Advanced analysis methods in high-energy physics}",
      booktitle      = "{Advanced computing and analysis techniques in physics
                        research. Proceedings, 7th International Workshop, ACAT
                        2000, Batavia, USA, October 16-20, 2000}",
      journal        = "AIP Conf. Proc.",
      volume         = "583",
      year           = "2001",
      pages          = "22-30",
      doi            = "10.1063/1.1405257, 10.1063/=",
      note           = "[,22(2001)]",
      eprint         = "hep-ex/0106099",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ex",
      reportNumber   = "FERMILAB-CONF-01-287",
}

@article{root,
      author         = "Brun, R. and Rademakers, F.",
      title          = "{ROOT: An object oriented data analysis framework}",
      booktitle      = "{New computing techniques in physics research V.
                        Proceedings, 5th International Workshop, AIHENP '96,
                        Lausanne, Switzerland, September 2-6, 1996}",
      journal        = "Nucl. Instrum. Meth.",
      volume         = "A389",
      year           = "1997",
      pages          = "81-86",
      doi            = "10.1016/S0168-9002(97)00048-X",
}

@book{effectivejava,
   title = "Effective Java : programming language guide",
   author = "Bloch, Joshua and Steele, Guy L.",
   series = "The Java Series",
   publisher = "Addison-Wesley",
   address = "Boston (Mass.), Toronto, Paris",
   url = "http://opac.inria.fr/record=b1097369",
   isbn = "0-201-31005-8",
   note = "La couv. porte : Foreword by Guy Steele",
   year = 2001
}

@article{lem-spark,
author = {Saba Sehrish and Jim Kowalkowski and Marc Paterno},
title = {Exploring the Performance of Spark for a Scientific Use Case},
journal = {2016 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW)},
volume = {00},
number = {undefined},
issn = {},
year = {2016},
pages = {1653-1659},
doi = {doi.ieeecomputersociety.org/10.1109/IPDPSW.2016.83},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
}

@article{cms,
  author={The CMS Collaboration and S Chatrchyan et. al.},
  title={{The CMS experiment at the CERN LHC}},
  journal={Journal of Instrumentation},
  volume={3},
  number={08},
  pages={S08004},
  url={http://stacks.iop.org/1748-0221/3/i=08/a=S08004},
  year={2008},
  abstract={The Compact Muon Solenoid (CMS) detector is described. The detector operates at the Large Hadron Collider (LHC) at CERN. It was conceived to study proton-proton (and lead-lead) collisions at a centre-of-mass energy of 14 TeV (5.5 TeV nucleon-nucleon) and at luminosities up to 10 34 cm −2 s −1 (10 27 cm −2 s −1 ). At the core of the CMS detector sits a high-magnetic-field and large-bore superconducting solenoid surrounding an all-silicon pixel and strip tracker, a lead-tungstate scintillating-crystals electromagnetic calorimeter, and a brass-scintillator sampling hadron calorimeter. The iron yoke of the flux-return is instrumented with four stations of muon detectors covering most of the 4π solid angle. Forward sampling calorimeters extend the pseudorapidity coverage to high values (|η| ≤ 5) assuring very good hermeticity. The overall dimensions of the CMS detector are a length of 21.6 m, a diameter of 14.6 m and a total weight of 12500 t.}
}

@article{cmss,
  author={P Elmer and B Hegner and L Sexton-Kennedy},
  title={Experience with the CMS event data model},
  journal={Journal of Physics: Conference Series},
  volume={219},
  number={3},
  pages={032022},
  url={http://stacks.iop.org/1742-6596/219/i=3/a=032022},
  year={2010},
  abstract={The re-engineered CMS EDM was presented at CHEP in 2006. Since that time we have gained a lot of operational experience with the chosen model. We will present some of our findings, and attempt to evaluate how well it is meeting its goals. We will discuss some of the new features that have been added since 2006 as well as some of the problems that have been addressed. Also discussed is the level of adoption throughout CMS, which spans the trigger farm up to the final physics analysis. Future plans, in particular dealing with schema evolution and scaling, will be discussed briefly.}
}

@article{cmstracking,
  author={{The CMS Collaboration}},
  title={Description and performance of track and primary-vertex reconstruction with the CMS tracker},
  journal={Journal of Instrumentation},
  volume={9},
  number={10},
  pages={P10009},
  url={http://stacks.iop.org/1748-0221/9/i=10/a=P10009},
  year={2014},
  abstract={A description is provided of the software algorithms developed for the CMS tracker both for reconstructing charged-particle trajectories in proton-proton interactions and for using the resulting tracks to estimate the positions of the LHC luminous region and individual primary-interaction vertices. Despite the very hostile environment at the LHC, the performance obtained with these algorithms is found to be excellent. For t ##IMG## [http://ej.iop.org/icons/Entities/bart.gif] {bar t} events under typical 2011 pileup conditions, the average track-reconstruction efficiency for promptly-produced charged particles with transverse momenta of p T > 0.9GeV is 94% for pseudorapidities of |η| < 0.9 and 85% for 0.9 < |η| < 2.5. The inefficiency is caused mainly by hadrons that undergo nuclear interactions in the tracker material. For isolated muons, the corresponding efficiencies are essentially 100%. For isolated muons of p T  = 100GeV emitted at |η| < 1.4, the resolutions are approximately 2.8% in p T , and respectively, 10μm and 30μm in the transverse and longitudinal impact parameters. The position resolution achieved for reconstructed primary vertices that correspond to interesting pp collisions is 10–12μm in each of the three spatial dimensions. The tracking and vertexing software is fast and flexible, and easily adaptable to other functions, such as fast tracking for the trigger, or dedicated tracking for electrons that takes into account bremsstrahlung.}
}

@article{cmsdata,
  author={Jennifer Adelman-McCarthy et. al.},
  title={CMS distributed computing workflow experience},
  journal={Journal of Physics: Conference Series},
  volume={331},
  number={7},
  pages={072019},
  url={http://stacks.iop.org/1742-6596/331/i=7/a=072019},
  year={2011},
  abstract={The vast majority of the CMS Computing capacity, which is organized in a tiered hierarchy, is located away from CERN. The 7 Tier-1 sites archive the LHC proton-proton collision data that is initially processed at CERN. These sites provide access to all recorded and simulated data for the Tier-2 sites, via wide-area network (WAN) transfers. All central data processing workflows are executed at the Tier-1 level, which contain re-reconstruction and skimming workflows of collision data as well as reprocessing of simulated data to adapt to changing detector conditions. This paper describes the operation of the CMS processing infrastructure at the Tier-1 level. The Tier-1 workflows are described in detail. The operational optimization of resource usage is described. In particular, the variation of different workflows during the data taking period of 2010, their efficiencies and latencies as well as their impact on the delivery of physics results is discussed and lessons are drawn from this experience. The simulation of proton-proton collisions for the CMS experiment is primarily carried out at the second tier of the CMS computing infrastructure. Half of the Tier-2 sites of CMS are reserved for central Monte Carlo (MC) production while the other half is available for user analysis. This paper summarizes the large throughput of the MC production operation during the data taking period of 2010 and discusses the latencies and efficiencies of the various types of MC production workflows. We present the operational procedures to optimize the usage of available resources and we the operational model of CMS for including opportunistic resources, such as the larger Tier-3 sites, into the central production operation.},
}

@Misc{olis-exascale-whitepaper,
   author = {Bloom K. and Gutsche O.},
   title = {{DOE} {SC} Exascale Requirements Reviews: High Energy Physics: Non-Traditional {HPC} Use Case: Energy Frontier Experiment},
   month = {June},
   year = {2015},
   howpublished = {\url{https://asset1.basecamp.com/2126401/projects/9226863/attachments/161144144}},
   }

@InProceedings{mr-hep,
	author=		{Fabian Glaser and Helmut Neukirchen and Thomas Rings and Jens Grabowski},
	title=		{{Using MapReduce for High Energy Physics Data Analysis}},
	year=		2013,
	month=		dec,
	keywords=	{MapReduce, Hadoop, Input format, ROOT, PROOF, High Energy Physics, Cloud computing},
	booktitle=	{
Proceedings of the 2013 International Symposium on MapReduce and Big Data Infrastructure (MR.BDI 2013), 03-05 December 2013, Sydney, Australia 2013
}
}

@misc{lhcgrid,
title = {{Worlwide LHC Computing Grid}},
howpublished={\url{http://wlcg.web.cern.ch}}
}
@misc{hllhc,
title = {{HL-LHC: High Luminosity Large Hadron Collider}},
howpublished={\url{http://hilumilhc.web.cern.ch}}
}

@misc{lhcmira, 
title = {Simulation of LHC events on a million threads},
howpublished={{https://indico.cern.ch/event/304944/session/8/contribution/536/attachments/578853/797048/TaylorChilders.MillionThreads.v3.pdf}}
}

@misc{tmva,
title = {{Toolkit for Multivariate Analysis (TMVA).}},
key = {{Toolkit for Multivariate Analysis (TMVA).}},
howpublished={\url{http://tmva.sourceforge.net}}
}

@misc{rootweb,
title = {{ROOT Data Analysis Framework.}},
key = {{ROOT.}},
howpublished={\url{http://root.cern.ch}}
}

@misc{sparkexa,
key = {{Exascale HPC Needs An Application Innovation Spark}},
title = {{Exascale HPC Needs An Application Innovation Spark}},
howpublished={\url{http://www.theplatform.net/2015/09/29/exascale-hpc-needs-an-application-innovation-spark/}}
}

@article{HEPadvana,
      author        = "Bhat, P C",
      title         = "{{Advanced Analysis Methods in High Energy Physics}}",
      journal       = "AIP Conf.Proc.",
      number        = {hep-ex/0106099. FERMILAB-CONF-2001-287},
      volume        = "583",
      pages         = "22-30. 9 p",
      year          = "2001",
      reportNumber  = {hep-ex/0106099},
      url           = "https://cds.cern.ch/record/506586",
      note          = {Comments: 9 pages, 5 figures, To be published in the
                       Proceedings of the VII International Workshop on Advanced
                       Computing and Analysis Techniques in Physics Research,
                       Fermilab, Oct. 16-20, 2000 (American Institute of Physics,
                       NY, 2001) edited by P.C. Bhat and M. Kasemann},
}

@incollection{deeplearninghiggs,
title = {{Searching for Higgs Boson Decay Modes with Deep Learning}},
author = {Sadowski, Peter J and Whiteson, Daniel and Baldi, Pierre},
booktitle = {Advances in Neural Information Processing Systems 27},
editor = {Z. Ghahramani and M. Welling and C. Cortes and N.D. Lawrence and K.Q. Weinberger},
pages = {2393--2401},
year = {2014},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/5351-searching-for-higgs-boson-decay-modes-with-deep-learning.pdf}
}

@article{deeplearninghep,
      author         = "Baldi, Pierre and Sadowski, Peter and Whiteson, Daniel",
      title          = "{Searching for Exotic Particles in High-Energy Physics
                        with Deep Learning}",
      journal        = "Nature Commun.",
      volume         = "5",
      year           = "2014",
      pages          = "4308",
      doi            = "10.1038/ncomms5308",
      eprint         = "1402.4735",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ph",
      SLACcitation   = "%%CITATION = ARXIV:1402.4735;%%"
}

@article{exabig,
 author = {Reed, Daniel A. and Dongarra, Jack},
 title = {Exascale Computing and Big Data},
 journal = {Communications of the ACM},
 issue_date = {July 2015},
 volume = {58},
 number = {7},
 month = jun,
 year = {2015},
 issn = {0001-0782},
 pages = {56--68},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/2699414},
 doi = {10.1145/2699414},
 acmid = {2699414},
 publisher = {ACM},
 address = {New York, NY, USA},
}

@book{noauthororeditorfourth,
  abstract = {Increasingly, scientific breakthroughs will be powered by advanced computing capabilities that help researchers manipulate and explore massive datasets.

The speed at which any given scientific discipline advances will depend on how well its researchers collaborate with one another, and with technologists, in areas of eScience such as databases, workflow management, visualization, and cloud computing technologies.

In The Fourth Paradigm: Data-Intensive Scientific Discovery, the collection of essays expands on the vision of pioneering computer scientist Jim Gray for a new, fourth paradigm of discovery based on data-intensive science and offers insights into how it can be fully realized.},
  added-at = {2010-02-16T09:54:37.000+0100},
  address = {Redmond, Washington},
  biburl = {http://www.bibsonomy.org/bibtex/28b203c0313656b6ced70c14c86a4c42a/acka47},
  editor = {Hey, Tony and Tansley, Stewart and Tolle, Kristin},
  interhash = {296450016ca8a5f8ab16ae4d92d1fc15},
  intrahash = {8b203c0313656b6ced70c14c86a4c42a},
  keywords = {research scholarly_communication science},
  publisher = {Microsoft Research},
  timestamp = {2010-02-16T09:54:54.000+0100},
  title = {The Fourth Paradigm: Data-Intensive Scientific Discovery},
  url = {http://research.microsoft.com/en-us/collaboration/fourthparadigm/},
  year = 2009
}

@article{higgsboson1,
      author         = "Chatrchyan, Serguei and others",
      title          = "{Observation of a new boson at a mass of 125 GeV with the
                        CMS experiment at the LHC}",
      collaboration  = "CMS",
      journal        = "Phys. Lett.",
      volume         = "B716",
      year           = "2012",
      pages          = "30-61",
      doi            = "10.1016/j.physletb.2012.08.021",
      eprint         = "1207.7235",
      archivePrefix  = "arXiv",
      primaryClass   = "hep-ex",
      reportNumber   = "CMS-HIG-12-028, CERN-PH-EP-2012-220",
}


